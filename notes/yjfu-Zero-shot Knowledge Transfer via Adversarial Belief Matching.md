@(论文2)[Zero-Shot KD|Knowledge Distilling]
#Zero-shot Knowledge Transfer via Adversarial Belief Matching
##Introduction
* 用一个对抗生成器去搜索那些最容易引起student和teacher不同的样本
##Method
* 他的搜索方式就是，分成两步，第一步是generator的训练，即generator不断地生成样本，然后希望自己生成的样本能让teacher和student表现不一样（把负的kl散度当做loss，即最大化kl散度）；第二步是student的训练，用generator生成的样本训练，希望能够最小化跟teacher输出的kl散度。这个结构是很优美的，但是可能有两个问题：一个是generator对空间的探索问题，有可能局限在某个区域内；而这同时会引起第二个问题，即student有可能跟teacher去刻画复杂边界，而这并不是我们的期望。
* fig1其实已经展现了一点这个问题，即generator生成的结果并不是均匀分布的。但是本身这个结果还是很漂亮的
###Potential conceptual concerns
* 这里讲了一些当把问题从toy数据集转换到高维数据的时候可能遇到的问题，这个讨论我觉得也是很有必要的。
* 第一个问题感觉就提的很尖锐，就是因为generator是从整个样本空间进行搜索的，所以很可能他探索的区域不在有意义图像所在的范围内，而学习这里的边界就不太有意义。
* 他的解释是，第一，在实践中发现即使是用真正的随机高斯噪声做训练也能达到一定的精度（因此无意义区域的拟合也有一定用处）；第二，他发现大部分的随机噪声会被分类为同一个类别（因此这种区域没什么好探索的，很快会探索完，然后开始探索复杂区域，即有意义的那部分）。第二点我感觉解释是有问题的，因为你的随机噪声都是同一个噪声采样出来的，比如高斯噪声，他的样本在空间里基本就围成了一个球，这个球所在的判别区域很可能就是一种，这解释不了这个问题。
* 第二个问题他大概指的是考虑到比如攻防对抗，改几个像素就能让某个网络完全判错的这种。他害怕生成器生成这种东西，相当于引入了噪声。他没怎么解释，只是实验结果说明，不会像他想的那么脆弱的。
##Experiments
* 提到，attention（某层特征的sum）是有效的。
* 看到了generator生成的样本，基本没什么意义，主要是纹理信息。
* **这里提到结果主要是高频信息。是否加入一个低频限制会好一些？**
* 又观察到，生成的样本在teacher中置信度（概率最高的输出）平均为0.8，而student为0.3，即主要是根据student的边缘挑的。这不知道为啥，可能是因为teacher比student深，训练生成器时反向传播的梯度很小，导致student的梯度占主导？
* 观察到生成的结果中，还是按照最高的输出来算，不同的类别的出现概率是一样的。这个很自然的就达到了这种平衡是很值得想一想的。
* 做了这样的实验：用类似于对抗攻击的方式让一张图片在student的预测改变，观察teacher对这个图片的变化情况。发现他的一致性更强。同时也发现，任务越复杂一致性越差。
# Paper reading list
1. Private Model Compression via Knowledge Distillation
2. MODEL COMPRESSION VIA DISTILLATION AND QUANTIZATION
